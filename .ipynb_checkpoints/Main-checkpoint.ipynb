{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db8e4ee",
   "metadata": {},
   "source": [
    "# COGS 181 Neural Networks & Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e337f",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f40ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a15c4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "def display_image(tsr_img):\n",
    "    plt.imshow(tsr_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b2272",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7514f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  360\n"
     ]
    }
   ],
   "source": [
    "# CNN Configuration\n",
    "\n",
    "labels_path = 'data/labels/clothing.csv'\n",
    "img_dir = 'data/data_cnn'\n",
    "all_images_dir = 'classification/images'\n",
    "training_ratio = 0.85\n",
    "\n",
    "# GAN Configuration\n",
    "\n",
    "dataroot = 'data/data_gan'\n",
    "workers = 2\n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "num_epochs = 5\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "ngpu = 1\n",
    "\n",
    "# Random seed\n",
    "manualSeed = 360\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53c79d",
   "metadata": {},
   "source": [
    "## Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c1c7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_seq = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6f0b1",
   "metadata": {},
   "source": [
    "## Loading CNN Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470c538",
   "metadata": {},
   "source": [
    "### Copy all classified images into `img_dir`\n",
    "\n",
    "Because I have given these images labels by hand, there are a few that have not been classified.\n",
    "\n",
    "After hand-classifying about 5000 of the images, I decided it would be better to finish the code implementation first before focusing on classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "625ddb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove all existing image copies from img_dir\n",
    "if os.path.exists(img_dir):\n",
    "    os.system(f'Remove-Item {img_dir}/*')\n",
    "else:\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "# copy all classified images into img_dir\n",
    "labels = pd.read_csv(labels_path, header=None)\n",
    "\n",
    "for img_filename in labels[0]:\n",
    "    # copy file from all_images_dir to img_dir\n",
    "    source = os.path.join(all_images_dir, img_filename)\n",
    "    destination = os.path.join(img_dir, img_filename)\n",
    "    shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60ec25",
   "metadata": {},
   "source": [
    "### Load image characteristics\n",
    "\n",
    "While the image dataset did not come with the labels that I intended to use, I decided it would still benefit the algorithm to have access to other features that **did** come with the data. \n",
    "\n",
    "The two features that are available are what type of clothing is pictured and whether or not the clothing is for a child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10a2e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_characteristics = pd.read_csv('data/archives/archive/images.csv')\n",
    "\n",
    "# clean and format image data\n",
    "clothing_characteristics.sort_values(by=['image'], inplace=True)\n",
    "clothing_characteristics.reset_index(inplace=True)\n",
    "clothing_characteristics.drop(columns=['index', 'sender_id'], inplace=True)\n",
    "\n",
    "# rename columns\n",
    "clothing_characteristics.columns = ['image', 'type', 'kids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c530455",
   "metadata": {},
   "source": [
    "### Clean data & one-hot encode type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2850ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = clothing_characteristics['type'].copy()\n",
    "\n",
    "# create matrix of zeros, size: (rows x types)\n",
    "encoded = np.zeros((len(types), len(types.unique())))\n",
    "\n",
    "# set index at type of clothing to 1, all others 0\n",
    "# this loop takes a few seconds\n",
    "for idx in range(len(types)):\n",
    "    encoded[idx][list(types.unique()).index(types[idx])] = 1\n",
    "\n",
    "# concatenate the encoded features\n",
    "clothing_characteristics = pd.concat([clothing_characteristics, pd.DataFrame(encoded)], axis=1)\n",
    "\n",
    "# rename the columns\n",
    "clothing_characteristics.columns = np.concatenate((clothing_characteristics.columns[:3], types.unique()))\n",
    "\n",
    "# ensure all columns use underscores instead of spaces and dashes\n",
    "clothing_characteristics.columns = [c.lower().replace('-', '_').replace(' ', '_') for c in clothing_characteristics.columns]\n",
    "\n",
    "# remove the original type column\n",
    "clothing_characteristics.drop(columns=['type'], inplace=True)\n",
    "\n",
    "# convert the kids column to 1 or 0\n",
    "clothing_characteristics['kids'] = clothing_characteristics['kids'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b494d70",
   "metadata": {},
   "source": [
    "### Creating custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b46b9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, header=None)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddab2a6",
   "metadata": {},
   "source": [
    "### Loading images into custom PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "baa61e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a custom dataset\n",
    "dataset_cnn = CustomImageDataset(labels_path, img_dir, transform_seq)\n",
    "\n",
    "# Split up the data into testing and training data\n",
    "dataset_size_cnn = dataset.__len__()\n",
    "training_size_cnn = math.floor(dataset_size_cnn * training_ratio)\n",
    "test_size_cnn = dataset_size_cnn - training_size_cnn\n",
    "\n",
    "training_data_cnn, test_data_cnn = torch.utils.data.random_split(dataset_cnn, [training_size_cnn, test_size_cnn])\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader_cnn = DataLoader(training_data_cnn, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "test_dataloader_cnn = DataLoader(test_data_cnn, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "all_dataloader_cnn = DataLoader(dataset_cnn, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75fcc6",
   "metadata": {},
   "source": [
    "## Loading DCGAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28b29490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gan = dset.ImageFolder(root='data/data_gan',transform=transform_seq)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader_gan = torch.utils.data.DataLoader(dataset_gan, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdb6a7",
   "metadata": {},
   "source": [
    "## DCGAN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6dc94ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ba0993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09f475d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "    \n",
    "netG.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7b7fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d65f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "netD.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "02dadb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f6eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print('Starting training loop...')\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, data in enumerate(dataloader_gan, 0):\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader),errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        if (iters % 100 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2f40f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bd7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/5][0/36]\tLoss_D: 1.7020\tLoss_G: 5.3204\tD(x): 0.4853\tD(G(z)): 0.5121 / 0.0074\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08f068",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[[1] Optimal ratio for data splitting](https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11583)\n",
    "\n",
    "[[2] DCGAN Tutorial - PyTorch](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "[[3] Implementing Generative Adversarial Networks (GANs) for Increasing a Convolutional Neural Network’s (CNN) Performance](https://12ft.io/proxy?q=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-generative-adversarial-networks-gans-for-increasing-a-convolutional-neural-networks-f871e17fe271)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
