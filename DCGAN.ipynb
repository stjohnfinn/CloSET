{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db8e4ee",
   "metadata": {},
   "source": [
    "# COGS 181 Neural Networks & Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609edb9d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e337f",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28f40ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.io import read_image, ImageReadMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a15c4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db74841",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7a71eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  360\n"
     ]
    }
   ],
   "source": [
    "# General Configuration\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 15\n",
    "image_size = 64\n",
    "\n",
    "# GAN Configuration\n",
    "\n",
    "dataroot = 'data/data_gan'\n",
    "nc = 3\n",
    "nz = 128\n",
    "ngf = 72\n",
    "ndf = 72\n",
    "beta1 = 0.7\n",
    "ngpu = 1\n",
    "lr_gan = 0.0004\n",
    "\n",
    "# Random seed\n",
    "manualSeed = 360\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be1c7c",
   "metadata": {},
   "source": [
    "### Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6f77fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_seq = transforms.Compose([\n",
    "    transforms.Resize(image_size, antialias=True),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f70db",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e154bf",
   "metadata": {},
   "source": [
    "### Loading DCGAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "28b29490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gan = dset.ImageFolder(root=dataroot,transform=transform_seq)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader_gan = torch.utils.data.DataLoader(dataset_gan, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31864b51",
   "metadata": {},
   "source": [
    "### DCGAN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6dc94ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize special weight creation for both discriminator and generator\n",
    "\n",
    "def weights_init(w):\n",
    "    label = w.__class__.__name__\n",
    "    \n",
    "    if label.find('Conv') != -1:\n",
    "        nn.init.normal_(w.weight.data, 0.0, 0.02)\n",
    "        \n",
    "    elif label.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(w.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(w.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6ba0993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 2, 0, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=True),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d7b7fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8d65f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "netG.apply(weights_init);\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "netD.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "02dadb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr_gan, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr_gan, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "800449ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD.to(device)\n",
    "netG.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "45e79214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print('Starting training loop...')\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, data in enumerate(dataloader_gan, 0):\n",
    "        \n",
    "        # this first set of samples will be real data\n",
    "        netD.zero_grad()\n",
    "        # send data to GPU\n",
    "        real_cpu = data[0].to(device)\n",
    "        \n",
    "        b_size = real_cpu.size(0)\n",
    "        \n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float64, device=device)\n",
    "        # predict on sample with discriminator\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        \n",
    "        # calculate the loss for this sample\n",
    "        errD_real = criterion(output, label)\n",
    "        \n",
    "        # backpropogate the loss through the network\n",
    "        errD_real.backward()\n",
    "        \n",
    "        \n",
    "        # second set of samples will be fake or generated data\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # generate fake set of data\n",
    "        fake = netG(noise)\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        # attempt to predict fake data with discriminator\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        \n",
    "        # calculate the loss of discrimninator\n",
    "        errD_fake = criterion(output, label)\n",
    "        # backpropogate the loss to discriminator\n",
    "        errD_fake.backward()\n",
    "        # update the weights\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # now update the generator with loss\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        label.fill_(real_label)\n",
    "        \n",
    "        output = netD(fake).view(-1)\n",
    "        \n",
    "        # calculate loss so far\n",
    "        errG = criterion(output, label)\n",
    "        \n",
    "        # backpropogate loss\n",
    "        errG.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # output every 100 batches in order to see progress\n",
    "        if i % 100 == 0:\n",
    "            print('Working...')\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08f068",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[[1] Optimal ratio for data splitting](https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11583)\n",
    "\n",
    "[[2] DCGAN Tutorial - PyTorch](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "[[3] Implementing Generative Adversarial Networks (GANs) for Increasing a Convolutional Neural Networkâ€™s (CNN) Performance](https://12ft.io/proxy?q=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-generative-adversarial-networks-gans-for-increasing-a-convolutional-neural-networks-f871e17fe271)\n",
    "\n",
    "[[3] Convolutional Neural Networks](https://12ft.io/proxy?q=https%3A%2F%2Fmedium.com%2Fswlh%2Ftraining-deep-neural-networks-on-a-gpu-with-pytorch-11079d89805)\n",
    "\n",
    "https://towardsdatascience.com/complete-guide-to-adam-optimization-1e5f29532c3d\n",
    "\n",
    "https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb95b7b",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "[Fashionpedia](https://fashionpedia.github.io/home/Fashionpedia_download.html)\n",
    "\n",
    "[Clothing Dataset - Kaggle](https://www.kaggle.com/datasets/agrigorev/clothing-dataset-full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
